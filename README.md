# Question-Answering-with-transformers
Fine tuning Huggingface's Roberta LLM on physics data using Pytorch

This project demonstrates how to perform question answering using transformers, specifically leveraging the Hugging Face Transformers library. It utilizes a pre-trained model for question answering and showcases how to tokenize inputs, process model outputs, and obtain the predicted answer.

# Customizations
- You can modify the questions and contexts in the Physics_questions list to suit your specific needs.

- If you want to use a different pre-trained model, you can update the model_name variable in the main.py file.

- Adjusting the maximum input length of the tokenizer can be done by modifying the value of tokenizer.model_max_length in the main.py file.

# Contributions 
Contributions are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request.
